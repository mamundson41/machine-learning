{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import misc\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, merge, Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten\n",
    "import cPickle as pickle\n",
    "data = pickle.load(open('data.p', 'rb'))\n",
    "test_data = pickle.load(open('test_data.p', 'rb'))\n",
    "extra = pickle.load(open('extra.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Read image data into numpy array\n",
    "def image_read(name_data, path):\n",
    "    image_list = []\n",
    "    for image_name in name_data:\n",
    "        image_list.append(misc.imread(path+image_name))\n",
    "    return np.asarray(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Shrinks image down to 54x54 based on bbox.  Reformats charecter bboxes to be ratio of new bbox.\n",
    "def crop_scale(data):\n",
    "    data['boxes']= [None]*len(data['image'])\n",
    "    for index in range(0,len(data['image'])):\n",
    "        top=int(max(data['top'][index].min(),0))\n",
    "        bottom = int(data['bottom'][index].max())\n",
    "        left = int(max(data['left'][index].min(),0))\n",
    "        right = int(data['right'][index].max())\n",
    "        width = right - left\n",
    "        height = bottom - top\n",
    "        data['image'][index] = data['image'][index][top:bottom,left:right,:]\n",
    "        data['image'][index] = misc.imresize(data['image'][index],(54,54),interp='bicubic')\n",
    "        null = np.full((5-len(data['top'][index])),-.5)\n",
    "        data['boxes'][index] = np.concatenate((np.concatenate((np.divide(np.subtract(data['top'][index],top),height),null)),\n",
    "        np.concatenate((np.divide(np.subtract(data['bottom'][index],top),height),null)),\n",
    "        np.concatenate((np.divide(np.subtract(data['left'][index],left),width),null)),\n",
    "        np.concatenate((np.divide(np.subtract(data['right'][index],left),width),null))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## One hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]] [ 4.  0.  0.  0.  0.  5.]\n"
     ]
    }
   ],
   "source": [
    "num_out = 6\n",
    "data['unified_label'][29929,5]=5.0\n",
    "data['hot_label'] = np.zeros((data['unified_label'].shape[0],num_out,11))\n",
    "test_data['hot_label'] = np.zeros((test_data['unified_label'].shape[0],num_out,11))\n",
    "for digit in range(0,num_out):\n",
    "    #print data['unified_label'].shape\n",
    "    data['hot_label'][:,digit,:] = np_utils.to_categorical(data['unified_label'][:,digit],11)\n",
    "    test_data['hot_label'][:,digit,:] = np_utils.to_categorical(test_data['unified_label'][:,digit],11)\n",
    "print data['hot_label'][29929],data['unified_label'][29929]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "def large_cnn(num_outs):\n",
    "    input_img=Input(shape=(54,54,3))\n",
    "    con1 = Convolution2D(16, 9, 9, border_mode='valid', activation='relu')(input_img)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(con1)\n",
    "    bnorm1 = BatchNormalization()(pool1)\n",
    "    con2 = Convolution2D(32, 5, 5, border_mode='valid', activation='relu')(bnorm1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(con2)\n",
    "    bnorm2 = BatchNormalization()(pool2)\n",
    "    drop1 = Dropout(0.4)(bnorm2)\n",
    "    con3 = Convolution2D(64, 3, 3, border_mode='valid', activation='relu')(drop1)\n",
    "    bnorm3 = BatchNormalization()(con3)\n",
    "    flat = Flatten()(bnorm3)\n",
    "    den1 = Dense(128, activation='relu')(flat)\n",
    "    den2 = Dense(128, activation='relu')(den1)\n",
    "    drop2 = Dropout(0.4)(den2)\n",
    "    output = Dense(20)(drop2)\n",
    "    model = Model(input=input_img, output=output)\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1043 105 938\n",
      "3360/3360 [==============================] - 70s      \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "0.0424199535378\n",
      "['loss']\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'train/train/129255.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ee5c7427cb6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mcrop_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m#batch['label_list']=[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-b428c8eed424>\u001b[0m in \u001b[0;36mimage_read\u001b[0;34m(name_data, path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimage_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senior/anaconda2/lib/python2.7/site-packages/scipy/misc/pilutil.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(name, flatten, mode)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/senior/anaconda2/lib/python2.7/site-packages/PIL/Image.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'train/train/129255.png'"
     ]
    }
   ],
   "source": [
    "from math import floor, ceil\n",
    "batch_size = 32\n",
    "train_path = 'train/train/'\n",
    "extra_path = 'extra/extra/'\n",
    "test_path = 'test/test/'\n",
    "total_batches =int(floor(len(data['left'])/batch_size))\n",
    "extra_batches = int(floor(len(extra['left'])/batch_size))\n",
    "val_batches=int(ceil(0.1*total_batches))\n",
    "train_batches=int(floor(0.9*total_batches))\n",
    "print total_batches,val_batches, train_batches\n",
    "batch = {}\n",
    "# build the model\n",
    "conv_net = large_cnn(6)\n",
    "\n",
    "for epoch in xrange(1):\n",
    "    for batch_itr in range(0, train_batches):\n",
    "        start_index = batch_itr*batch_size\n",
    "        stop_index = (batch_itr+1)*batch_size\n",
    "        for key in data:\n",
    "            batch[key]=data[key][start_index:stop_index]\n",
    "        batch['image']=image_read(batch['names'],train_path)\n",
    "        crop_scale(batch)\n",
    "        #batch['label_list']=[]\n",
    "        #for itr in range(0,5):\n",
    "            #batch['label_list'].append(batch['hot_label'][:,itr,:])\n",
    "        #batch['label_list'].append(batch['hot_label'][:,5,1:6])\n",
    "        #batch['label_list'].append(np.stack(batch['boxes']))\n",
    "        batch['image'] = np.stack(batch['image'])/255.0-0.5\n",
    "        # Fit the model\n",
    "        conv_net.train_on_batch(batch['image'],np.stack(batch['boxes']))\n",
    "        \n",
    "    #validation test\n",
    "    start_index = train_batches*batch_size\n",
    "    stop_index = (total_batches)*batch_size\n",
    "    for key in data:\n",
    "        batch[key]=data[key][start_index:stop_index]\n",
    "    batch['image']=image_read(batch['names'],train_path)\n",
    "    crop_scale(batch)\n",
    "    batch['label_list']=[]\n",
    "    for itr in range(0,5):\n",
    "        batch['label_list'].append(batch['hot_label'][:,itr,:])\n",
    "    batch['label_list'].append(batch['hot_label'][:,5,1:6])\n",
    "    batch['label_list'].append(np.stack(batch['boxes']))\n",
    "    batch['image'] = np.stack(batch['image'])/255.0-0.5\n",
    "    # Fit the model\n",
    "    print conv_net.evaluate(batch['image'],np.stack(batch['boxes']),batch_size=400)\n",
    "    print conv_net.metrics_names    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_itr in range(0, extra_batches):\n",
    "    start_index = batch_itr*batch_size\n",
    "    stop_index = (batch_itr+1)*batch_size\n",
    "    for key in extra:\n",
    "        batch[key]=extra[key][start_index:stop_index]\n",
    "    batch['image']=image_read(batch['names'],extra_path)\n",
    "    crop_scale(batch)\n",
    "    #batch['label_list']=[]\n",
    "    #for itr in range(0,5):\n",
    "        #batch['label_list'].append(batch['hot_label'][:,itr,:])\n",
    "    #batch['label_list'].append(batch['hot_label'][:,5,1:6])\n",
    "    #batch['label_list'].append(np.stack(batch['boxes']))\n",
    "    batch['image'] = np.stack(batch['image'])/255.0-0.5\n",
    "    # Fit the model\n",
    "    conv_net.train_on_batch(batch['image'],np.stack(batch['boxes']))\n",
    "\n",
    "\n",
    "#validation test\n",
    "start_index = train_batches*batch_size\n",
    "stop_index = (total_batches)*batch_size\n",
    "for key in data:\n",
    "    batch[key]=data[key][start_index:stop_index]\n",
    "batch['image']=image_read(batch['names'],train_path)\n",
    "crop_scale(batch)\n",
    "batch['label_list']=[]\n",
    "for itr in range(0,5):\n",
    "    batch['label_list'].append(batch['hot_label'][:,itr,:])\n",
    "batch['label_list'].append(batch['hot_label'][:,5,1:6])\n",
    "batch['label_list'].append(np.stack(batch['boxes']))\n",
    "batch['image'] = np.stack(batch['image'])/255.0-0.5\n",
    "# Fit the model\n",
    "predictions = conv_net.predict(batch['image'], batch_size=batch_size)\n",
    "print conv_net.evaluate(batch['image'],np.stack(batch['boxes']),batch_size=400)\n",
    "print conv_net.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360/3360 [==============================] - 20s     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "0.0243150021083\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print conv_net.evaluate(batch['image'],np.stack(batch['boxes']),batch_size=400)\n",
    "print conv_net.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_net.save('BBR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "conv_net = keras.models.load_model('BBR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0319836 0.962071 -0.0631097 0.388478\n",
      "0.0 0.982062780269 0.0 0.468208092486\n",
      "[  0.69681663   0.50110441 -68.89629574  18.42322515  -0.        ]\n"
     ]
    }
   ],
   "source": [
    "batch = {}\n",
    "start_index = 0\n",
    "stop_index = 10\n",
    "train_path = 'train/train/'\n",
    "for key in data:\n",
    "    batch[key]=data[key][start_index:stop_index]\n",
    "batch['image']=image_read(batch['names'],train_path)\n",
    "crop_scale(batch)\n",
    "batch['label_list']=[]\n",
    "for itr in range(0,5):\n",
    "    batch['label_list'].append(batch['hot_label'][:,itr,:])\n",
    "batch['label_list'].append(batch['hot_label'][:,5,1:6])\n",
    "batch['label_list'].append(np.stack(batch['boxes']))\n",
    "batch['image'] = np.stack(batch['image'])/255.0-0.5\n",
    "# Fit the model\n",
    "output =  conv_net.predict(batch['image'])\n",
    "print output[6][0][0],output[6][0][5],output[6][0][10],output[6][0][15]\n",
    "print batch['boxes'][0][0],batch['boxes'][0][5],batch['boxes'][0][10],batch['boxes'][0][15]\n",
    "print iou(output[6][0],batch['boxes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.612111344783\n",
      "[ 2.  9.  4.  0.  0.  3.]\n",
      "3360\n"
     ]
    }
   ],
   "source": [
    "#Evaluate average IOU\n",
    "total_iou = 0.0\n",
    "total_digits = 0.0\n",
    "for itr in xrange(len(predictions)):\n",
    "    seq_iou = iou(predictions[itr],batch['boxes'][itr])\n",
    "    #print sum(seq_iou[0:int(batch['unified_label'][itr][5])])\n",
    "    total_iou += sum(seq_iou[0:int(batch['unified_label'][itr][5])])\n",
    "    total_digits += batch['unified_label'][itr][5]\n",
    "print total_iou/total_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#batch['image'] = np.stack(batch['image'])/255.0-1.0\n",
    "for itr in xrange(100):\n",
    "    plt.figure()\n",
    "    plt.imshow(batch['image'][itr])\n",
    "    print batch['label'][itr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Final evaluation of the model MNIST\n",
    "predictions = conv_net.predict(test_data,batch_size=200, verbose=1)\n",
    "combined_pred = np.array(predictions).argmax(axis=2).T\n",
    "equiv = combined_pred==label_test\n",
    "print 'digit acc' , float(np.sum(equiv))/10000\n",
    "seq_acc = np.sum((equiv.sum(axis=1)==5))/2000.0\n",
    "print 'sequence acc' , seq_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Intersection over union\n",
    "def iou(y_true, y_pred):\n",
    "    top_true = y_true[0:5]\n",
    "    bottom_true = y_true[5:10]\n",
    "    left_true = y_true[10:15]\n",
    "    right_true = y_true[15:20]\n",
    "    top_pred = y_pred[0:5]\n",
    "    bottom_pred = y_pred[5:10]\n",
    "    left_pred = y_pred[10:15]\n",
    "    right_pred = y_pred[15:20]\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    li = np.maximum(left_true, left_pred)\n",
    "    bi = np.minimum(bottom_true, bottom_pred)\n",
    "    ri = np.minimum(right_true, right_pred)\n",
    "    ti = np.maximum(top_true, top_pred)\n",
    "    #print ti[0],bi[0],li[0],ri[0]\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = np.multiply(np.subtract(ri , li) ,np.subtract(bi , ti))\n",
    "    #print interArea[0]\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    true_area = np.multiply(np.subtract(bottom_true,top_true),np.subtract(right_true,left_true)) +.00001\n",
    "    pred_area = np.multiply(np.subtract(bottom_pred,top_pred),np.subtract(right_pred,left_pred)) +.00001\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = np.divide(interArea,np.subtract(np.add(true_area, pred_area), interArea))\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 4\n",
    "_Describe how you set up the training and testing data for your model. How does the model perform on a realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## IOU\n",
    "Adrian Rosebrock\n",
    "http://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "Pixel coordinate refrences may be screwy if errors double check here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 5\n",
    "_What changes did you have to make, if any, to achieve \"good\" results? Were there any options you explored that made the results worse?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 6\n",
    "_What were your initial and final results with testing on a realistic dataset? Do you believe your model is doing a good enough job at classifying numbers correctly?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Step 3: Test a Model on Newly-Captured Images\n",
    "\n",
    "Take several pictures of numbers that you find around you (at least five), and run them through your classifier on your computer to produce example results. Alternatively (optionally), you can try using OpenCV / SimpleCV / Pygame to capture live images from a webcam and run those through your classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 7\n",
    "_Choose five candidate images of numbers you took from around you and provide them in the report. Are there any particular qualities of the image(s) that might make classification difficult?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 8\n",
    "_Is your model able to perform equally well on captured pictures or a live camera stream when compared to testing on the realistic dataset?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optional: Question 9\n",
    "_If necessary, provide documentation for how an interface was built for your model to load and classify newly-acquired images._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:** Leave blank if you did not complete this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "### Step 4: Explore an Improvement for a Model\n",
    "\n",
    "There are many things you can do once you have the basic classifier in place. One example would be to also localize where the numbers are on the image. The SVHN dataset provides bounding boxes that you can tune to train a localizer. Train a regression loss to the coordinates of the bounding box, and then test it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 10\n",
    "_How well does your model localize numbers on the testing set from the realistic dataset? Do your classification results change at all with localization included?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 11\n",
    "_Test the localization function on the images you captured in **Step 3**. Does the model accurately calculate a bounding box for the numbers in the images you found? If you did not use a graphical interface, you may need to investigate the bounding boxes by hand._ Provide an example of the localization created on a captured image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "----\n",
    "## Optional Step 5: Build an Application or Program for a Model\n",
    "Take your project one step further. If you're interested, look to build an Android application or even a more robust Python program that can interface with input images and display the classified numbers and even the bounding boxes. You can for example try to build an augmented reality app by overlaying your answer on the image like the [Word Lens](https://en.wikipedia.org/wiki/Word_Lens) app does.\n",
    "\n",
    "Loading a TensorFlow model into a camera app on Android is demonstrated in the [TensorFlow Android demo app](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android), which you can simply modify.\n",
    "\n",
    "If you decide to explore this optional route, be sure to document your interface and implementation, along with significant results you find. You can see the additional rubric items that you could be evaluated on by [following this link](https://review.udacity.com/#!/rubrics/413/view)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optional Implementation\n",
    "Use the code cell (or multiple code cells, if necessary) to implement the first step of your project. Once you have completed your implementation and are satisfied with the results, be sure to thoroughly answer the questions that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnCVvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08723f16d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0x+CWpMf8PMsVxcwFIJMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0904d6c9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0905f86210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0905ee6590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyLhLUkPGXZIaMu6S1JBxl6SG/g++lyNDlIALEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0871f78f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAzHwQ2loctiWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0905ee6390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.        ,  0.27671996,  0.18924017,  0.13017185,  0.10511347,\n",
      "        0.08469553,  0.06445722,  0.05619424,  0.04745225,  0.04344051,\n",
      "        0.00251482]), array([ 0.15379319,  0.09975451,  0.0937369 ,  0.08891683,  0.08403688,\n",
      "        0.085923  ,  0.0745165 ,  0.07903718,  0.07122328,  0.06828932,\n",
      "        0.10077241]), array([ 0.69657506,  0.03377043,  0.02942938,  0.03164481,  0.02930962,\n",
      "        0.03134543,  0.0285911 ,  0.02877073,  0.02814203,  0.02410035,\n",
      "        0.03832106]), array([ 0.95676906,  0.00467038,  0.00449075,  0.0035926 ,  0.00482007,\n",
      "        0.00401174,  0.00389198,  0.00344291,  0.00419137,  0.00362254,\n",
      "        0.00649662]), array([  9.99700617e-01,   5.98766541e-05,   0.00000000e+00,\n",
      "         5.98766541e-05,   0.00000000e+00,   5.98766541e-05,\n",
      "         0.00000000e+00,   5.98766541e-05,   0.00000000e+00,\n",
      "         2.99383270e-05,   2.99383270e-05]), array([  0.00000000e+00,   1.53793186e-01,   5.42781869e-01,\n",
      "         2.60194000e-01,   4.29315610e-02,   2.69444943e-04,\n",
      "         0.00000000e+00,   0.00000000e+00,   2.99383270e-05,\n",
      "         0.00000000e+00,   0.00000000e+00])]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "list_label = data['label'].tolist()\n",
    "digits = []\n",
    "digits = [[] for x in xrange(6)]\n",
    "for arr in list_label:\n",
    "    for digit in xrange(6):\n",
    "        digits[digit].append(arr[digit])\n",
    "\n",
    "class_weight = {}\n",
    "itr = 0\n",
    "for digit in digits:\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(digit, bins=11, normed=1, range=(-.5,10.5),facecolor='green')\n",
    "    class_weight[dense_11n)\n",
    "    plt.show()\n",
    "    itr++\n",
    "print probs\n",
    "#plt.xlabel('Smarts')\n",
    "#plt.ylabel('Probability')\n",
    "#plt.title(r'$\\mathrm{Histogram\\ of\\ IQ:}\\ \\mu=100,\\ \\sigma=15$')\n",
    "#plt.axis([40, 160, 0, 0.03])\n",
    "#plt.grid(True)\n",
    "\n",
    "\n",
    "#plt.scatter(range(0,len(data['label'])), length_list)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Your optional code implementation goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Documentation\n",
    "Provide additional documentation sufficient for detailing the implementation of the Android application or Python program for visualizing the classification of numbers in images. It should be clear how the program or application works. Demonstrations should be provided. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "_Write your documentation here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "> **Note**: Once you have completed all of the code implementations and successfully answered each question above, you may finalize your work by exporting the iPython Notebook as an HTML document. You can do this by using the menu above and navigating to  \n",
    "**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
