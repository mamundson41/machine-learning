{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition of multiple MNIST characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfmBpCg/kBTlB5Ki/EBSlB9I6v8BZOIGXzoUqLUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff2780adf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import mnist data from keras, view sample image\n",
    "from keras.datasets import mnist\n",
    "(image_train, label_train), (image_test, label_test)  =mnist.load_data()\n",
    "plt.figure()\n",
    "plt.imshow(image_train[2, :, :])\n",
    "print label_train[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print image_train.shape[0]\n",
    "print image_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate sequence images by concatenating 5 numbers and provides labels for those sequences\"\"\"\n",
    "def im_merge(im_in, label_in, num_out, max_num):\n",
    "    data = np.ndarray(shape=(num_out,28,140))\n",
    "    labels = np.ndarray(shape=(num_out,6))\n",
    "    for ctr in range(0,num_out):\n",
    "        im_list = []\n",
    "        label_list=[]\n",
    "        arr_len = im_in.shape[0]\n",
    "        num_dig = np.random.randint(3,max_num+1)\n",
    "        for itr in range(0,num_dig):\n",
    "            index = np.random.randint(0,arr_len)\n",
    "            im_list.append(im_in[index,:,:])\n",
    "            label_list.append(label_in[index])\n",
    "        concat = np.concatenate(im_list, axis=1)\n",
    "        full_im = np.zeros((28,140))\n",
    "        full_im[:,0:28*num_dig] += concat\n",
    "        data[ctr]= full_im\n",
    "        full_label = np.empty(6)\n",
    "        full_label.fill(10)\n",
    "        full_label[0:num_dig] = label_list\n",
    "        full_label[5]=num_dig\n",
    "        labels[ctr] = full_label\n",
    "    return data , labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   4.   0.  10.  10.   3.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABlCAYAAABdnhjZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH9paKOmfR3l5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbc38235b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_train = 40000\n",
    "num_test = 4000\n",
    "max_num = 5\n",
    "train_data, label_train = im_merge(image_train, label_train, num_train, max_num)\n",
    "test_data, label_test = im_merge(image_test, label_test, num_test, max_num)\n",
    "plt.figure()\n",
    "plt.imshow(train_data[2])\n",
    "print label_train[2]\n",
    "train_data = train_data/255\n",
    "test_data = test_data/255\n",
    "train_data = train_data.reshape(train_data.shape[0],1,train_data.shape[1],train_data.shape[2])\n",
    "test_data = test_data.reshape(test_data.shape[0],1,test_data.shape[1],test_data.shape[2]).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 1, 28, 140)\n"
     ]
    }
   ],
   "source": [
    "print train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   4.   0.  10.  10.   3.] [[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#One-hot encode the labels for training\n",
    "from keras.utils import np_utils\n",
    "hot_train = np.zeros((num_train,max_num+1,11))\n",
    "hot_test = np.zeros((num_test,max_num+1,11))\n",
    "for digit in range(0,len(label_train[0])):\n",
    "    hot_train[:,digit,:] = np_utils.to_categorical(label_train[:,digit],11)\n",
    "    hot_test[:,digit,:] = np_utils.to_categorical(label_test[:,digit],11)\n",
    "print label_train[2],hot_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put labels into list format for compatibility with keras.\n",
    "train_label_list = []\n",
    "test_label_list = []\n",
    "for itr in range(0,6):\n",
    "    train_label_list.append(hot_train[:,itr,:])\n",
    "    test_label_list.append(hot_test[:,itr,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the CNN architecture that gave me the best results.\n",
    "def large_cnn(num_outs):\n",
    "    input_img=Input(shape=(1,28,140))\n",
    "    con1 = Convolution2D(30, 5, 5, border_mode='valid', activation='relu', dim_ordering=\"th\")(input_img)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(con1)\n",
    "    con2 = Convolution2D(15, 3, 3, border_mode='valid', activation='relu', dim_ordering=\"th\")(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(con2)\n",
    "    drop1 = Dropout(0.4)(pool2)\n",
    "    flat = Flatten()(drop1)\n",
    "    den1 = Dense(128, activation='relu')(flat)\n",
    "    den2 = Dense(128, activation='relu')(den1)\n",
    "    drop2 = Dropout(0.4)(den2)\n",
    "    outputs = []\n",
    "    for itr in range(0,num_outs):\n",
    "        outputs.append(Dense(11, activation='softmax')(drop2))\n",
    "    model = Model(input=input_img, output=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (5, 5), padding=\"valid\", activation=\"relu\", data_format=\"channels_first\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  \"\"\"\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), padding=\"valid\", activation=\"relu\", data_format=\"channels_first\")`\n",
      "  \n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  import sys\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "  app.launch_new_instance()\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 145s - loss: 7.4257 - dense_3_loss: 1.6996 - dense_4_loss: 1.6341 - dense_5_loss: 1.6548 - dense_6_loss: 1.3438 - dense_7_loss: 0.8504 - dense_8_loss: 0.2431 - dense_3_acc: 0.4037 - dense_4_acc: 0.4218 - dense_5_acc: 0.4242 - dense_6_acc: 0.5539 - dense_7_acc: 0.7341 - dense_8_acc: 0.9410 - val_loss: 2.4946 - val_dense_3_loss: 0.5333 - val_dense_4_loss: 0.5185 - val_dense_5_loss: 0.5286 - val_dense_6_loss: 0.5324 - val_dense_7_loss: 0.3755 - val_dense_8_loss: 0.0062 - val_dense_3_acc: 0.8754 - val_dense_4_acc: 0.8697 - val_dense_5_acc: 0.8718 - val_dense_6_acc: 0.8620 - val_dense_7_acc: 0.8920 - val_dense_8_acc: 1.0000\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 18s - loss: 3.5008 - dense_3_loss: 0.7773 - dense_4_loss: 0.7634 - dense_5_loss: 0.7734 - dense_6_loss: 0.6543 - dense_7_loss: 0.4687 - dense_8_loss: 0.0637 - dense_3_acc: 0.7381 - dense_4_acc: 0.7443 - dense_5_acc: 0.7405 - dense_6_acc: 0.7825 - dense_7_acc: 0.8477 - dense_8_acc: 0.9782 - val_loss: 1.2065 - val_dense_3_loss: 0.2552 - val_dense_4_loss: 0.2521 - val_dense_5_loss: 0.2688 - val_dense_6_loss: 0.2457 - val_dense_7_loss: 0.1834 - val_dense_8_loss: 0.0012 - val_dense_3_acc: 0.9420 - val_dense_4_acc: 0.9394 - val_dense_5_acc: 0.9379 - val_dense_6_acc: 0.9412 - val_dense_7_acc: 0.9552 - val_dense_8_acc: 1.0000\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 18s - loss: 2.6273 - dense_3_loss: 0.5935 - dense_4_loss: 0.5758 - dense_5_loss: 0.5855 - dense_6_loss: 0.4782 - dense_7_loss: 0.3397 - dense_8_loss: 0.0548 - dense_3_acc: 0.8048 - dense_4_acc: 0.8076 - dense_5_acc: 0.8047 - dense_6_acc: 0.8424 - dense_7_acc: 0.8882 - dense_8_acc: 0.9800 - val_loss: 0.8372 - val_dense_3_loss: 0.1814 - val_dense_4_loss: 0.1822 - val_dense_5_loss: 0.1866 - val_dense_6_loss: 0.1664 - val_dense_7_loss: 0.1200 - val_dense_8_loss: 4.2639e-04 - val_dense_3_acc: 0.9559 - val_dense_4_acc: 0.9534 - val_dense_5_acc: 0.9539 - val_dense_6_acc: 0.9612 - val_dense_7_acc: 0.9734 - val_dense_8_acc: 1.0000\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 18s - loss: 2.2640 - dense_3_loss: 0.5102 - dense_4_loss: 0.5054 - dense_5_loss: 0.5194 - dense_6_loss: 0.4038 - dense_7_loss: 0.2755 - dense_8_loss: 0.0497 - dense_3_acc: 0.8278 - dense_4_acc: 0.8319 - dense_5_acc: 0.8307 - dense_6_acc: 0.8652 - dense_7_acc: 0.9093 - dense_8_acc: 0.9822 - val_loss: 0.6879 - val_dense_3_loss: 0.1543 - val_dense_4_loss: 0.1516 - val_dense_5_loss: 0.1553 - val_dense_6_loss: 0.1365 - val_dense_7_loss: 0.0899 - val_dense_8_loss: 3.2906e-04 - val_dense_3_acc: 0.9626 - val_dense_4_acc: 0.9626 - val_dense_5_acc: 0.9607 - val_dense_6_acc: 0.9677 - val_dense_7_acc: 0.9812 - val_dense_8_acc: 1.0000\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 18s - loss: 2.0580 - dense_3_loss: 0.4764 - dense_4_loss: 0.4563 - dense_5_loss: 0.4527 - dense_6_loss: 0.3762 - dense_7_loss: 0.2498 - dense_8_loss: 0.0466 - dense_3_acc: 0.8426 - dense_4_acc: 0.8483 - dense_5_acc: 0.8525 - dense_6_acc: 0.8790 - dense_7_acc: 0.9184 - dense_8_acc: 0.9841 - val_loss: 0.5944 - val_dense_3_loss: 0.1353 - val_dense_4_loss: 0.1330 - val_dense_5_loss: 0.1375 - val_dense_6_loss: 0.1142 - val_dense_7_loss: 0.0743 - val_dense_8_loss: 1.4846e-04 - val_dense_3_acc: 0.9642 - val_dense_4_acc: 0.9651 - val_dense_5_acc: 0.9634 - val_dense_6_acc: 0.9735 - val_dense_7_acc: 0.9850 - val_dense_8_acc: 1.0000\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 18s - loss: 1.9342 - dense_3_loss: 0.4476 - dense_4_loss: 0.4297 - dense_5_loss: 0.4331 - dense_6_loss: 0.3466 - dense_7_loss: 0.2322 - dense_8_loss: 0.0449 - dense_3_acc: 0.8524 - dense_4_acc: 0.8592 - dense_5_acc: 0.8576 - dense_6_acc: 0.8847 - dense_7_acc: 0.9238 - dense_8_acc: 0.9839 - val_loss: 0.5383 - val_dense_3_loss: 0.1261 - val_dense_4_loss: 0.1181 - val_dense_5_loss: 0.1232 - val_dense_6_loss: 0.1041 - val_dense_7_loss: 0.0668 - val_dense_8_loss: 9.3025e-05 - val_dense_3_acc: 0.9659 - val_dense_4_acc: 0.9696 - val_dense_5_acc: 0.9662 - val_dense_6_acc: 0.9735 - val_dense_7_acc: 0.9841 - val_dense_8_acc: 1.0000\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 18s - loss: 1.8304 - dense_3_loss: 0.4201 - dense_4_loss: 0.4058 - dense_5_loss: 0.4067 - dense_6_loss: 0.3328 - dense_7_loss: 0.2204 - dense_8_loss: 0.0446 - dense_3_acc: 0.8619 - dense_4_acc: 0.8652 - dense_5_acc: 0.8654 - dense_6_acc: 0.8886 - dense_7_acc: 0.9278 - dense_8_acc: 0.9840 - val_loss: 0.4892 - val_dense_3_loss: 0.1122 - val_dense_4_loss: 0.1134 - val_dense_5_loss: 0.1100 - val_dense_6_loss: 0.0927 - val_dense_7_loss: 0.0607 - val_dense_8_loss: 1.3550e-04 - val_dense_3_acc: 0.9706 - val_dense_4_acc: 0.9699 - val_dense_5_acc: 0.9709 - val_dense_6_acc: 0.9772 - val_dense_7_acc: 0.9859 - val_dense_8_acc: 1.0000\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 18s - loss: 1.7214 - dense_3_loss: 0.3935 - dense_4_loss: 0.3844 - dense_5_loss: 0.3862 - dense_6_loss: 0.3093 - dense_7_loss: 0.2061 - dense_8_loss: 0.0419 - dense_3_acc: 0.8688 - dense_4_acc: 0.8747 - dense_5_acc: 0.8724 - dense_6_acc: 0.8975 - dense_7_acc: 0.9329 - dense_8_acc: 0.9847 - val_loss: 0.4670 - val_dense_3_loss: 0.1061 - val_dense_4_loss: 0.1052 - val_dense_5_loss: 0.1053 - val_dense_6_loss: 0.0909 - val_dense_7_loss: 0.0594 - val_dense_8_loss: 9.0101e-05 - val_dense_3_acc: 0.9709 - val_dense_4_acc: 0.9726 - val_dense_5_acc: 0.9724 - val_dense_6_acc: 0.9764 - val_dense_7_acc: 0.9866 - val_dense_8_acc: 1.0000\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 18s - loss: 1.6559 - dense_3_loss: 0.3765 - dense_4_loss: 0.3675 - dense_5_loss: 0.3714 - dense_6_loss: 0.2962 - dense_7_loss: 0.2048 - dense_8_loss: 0.0395 - dense_3_acc: 0.8734 - dense_4_acc: 0.8808 - dense_5_acc: 0.8777 - dense_6_acc: 0.9029 - dense_7_acc: 0.9323 - dense_8_acc: 0.9856 - val_loss: 0.4325 - val_dense_3_loss: 0.0984 - val_dense_4_loss: 0.0981 - val_dense_5_loss: 0.0975 - val_dense_6_loss: 0.0830 - val_dense_7_loss: 0.0554 - val_dense_8_loss: 1.5457e-04 - val_dense_3_acc: 0.9747 - val_dense_4_acc: 0.9746 - val_dense_5_acc: 0.9726 - val_dense_6_acc: 0.9794 - val_dense_7_acc: 0.9877 - val_dense_8_acc: 1.0000\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 18s - loss: 1.5827 - dense_3_loss: 0.3596 - dense_4_loss: 0.3554 - dense_5_loss: 0.3518 - dense_6_loss: 0.2866 - dense_7_loss: 0.1911 - dense_8_loss: 0.0381 - dense_3_acc: 0.8798 - dense_4_acc: 0.8827 - dense_5_acc: 0.8841 - dense_6_acc: 0.9043 - dense_7_acc: 0.9372 - dense_8_acc: 0.9858 - val_loss: 0.4243 - val_dense_3_loss: 0.0983 - val_dense_4_loss: 0.0969 - val_dense_5_loss: 0.0966 - val_dense_6_loss: 0.0816 - val_dense_7_loss: 0.0507 - val_dense_8_loss: 2.1963e-04 - val_dense_3_acc: 0.9759 - val_dense_4_acc: 0.9747 - val_dense_5_acc: 0.9746 - val_dense_6_acc: 0.9795 - val_dense_7_acc: 0.9892 - val_dense_8_acc: 1.0000\n",
      "3600/4000 [==========================>...] - ETA: 0sdigit acc 2.357\n",
      "sequence acc 0.2\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "conv_net = large_cnn(6)\n",
    "# Fit the model\n",
    "conv_net.fit(train_data, train_label_list, nb_epoch=10, batch_size=200, verbose=1, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s     \n",
      "digit accuracy 0.9785\n",
      "sequence accuracy 0.89625\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "predictions = conv_net.predict(test_data,batch_size=200, verbose=1)\n",
    "combined_pred = np.array(predictions[0:5]).argmax(axis=2).T\n",
    "equiv = combined_pred==label_test[:,0:5]\n",
    "print 'digit accuracy' , float(np.sum(equiv))/(5*num_test)\n",
    "seq_acc = np.sum((equiv.sum(axis=1)==5))/float(num_test)\n",
    "print 'sequence accuracy' , seq_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# digit accuracy 0.9785 sequence accuracy 0.89625\n",
    "### The following network architectures were also tried and the results are shown below.\n",
    "### Inception like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception(num_outs):\n",
    "    input_img=Input(shape=(1,28,140))\n",
    "    tower_1 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\n",
    "    tower_1 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_1)\n",
    "\n",
    "    tower_2 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\n",
    "    tower_2 = Convolution2D(64, 5, 5, border_mode='same', activation='relu')(tower_2)\n",
    "\n",
    "    tower_3 = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same')(input_img)\n",
    "    tower_3 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(tower_3)\n",
    "\n",
    "    merged = concatenate([tower_1, tower_2, tower_3])\n",
    "    \n",
    "    flat = Flatten()(merged)\n",
    "    drop = Dropout(0.3)(flat)\n",
    "    next_rel = Dense(128,activation='relu')(drop)\n",
    "    outputs = []\n",
    "    for itr in range(0,num_outs):\n",
    "        outputs.append(Dense(11, activation='softmax')(next_rel))\n",
    "    model = Model(input=input_img, output=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  \n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")`\n",
      "  import sys\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), padding=\"same\", strides=(1, 1))`\n",
      "  if __name__ == '__main__':\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 5s - loss: 4.0036 - dense_30_loss: 0.8741 - dense_31_loss: 0.8953 - dense_32_loss: 0.8720 - dense_33_loss: 0.7382 - dense_34_loss: 0.5324 - dense_35_loss: 0.0918 - dense_30_acc: 0.7196 - dense_31_acc: 0.7091 - dense_32_acc: 0.7185 - dense_33_acc: 0.7608 - dense_34_acc: 0.8298 - dense_35_acc: 0.9739 - val_loss: 1.9429 - val_dense_30_loss: 0.4725 - val_dense_31_loss: 0.4131 - val_dense_32_loss: 0.4723 - val_dense_33_loss: 0.3452 - val_dense_34_loss: 0.2352 - val_dense_35_loss: 0.0046 - val_dense_30_acc: 0.8585 - val_dense_31_acc: 0.8744 - val_dense_32_acc: 0.8529 - val_dense_33_acc: 0.8954 - val_dense_34_acc: 0.9270 - val_dense_35_acc: 0.9994\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 4s - loss: 1.7823 - dense_30_loss: 0.4190 - dense_31_loss: 0.4124 - dense_32_loss: 0.4223 - dense_33_loss: 0.3147 - dense_34_loss: 0.2088 - dense_35_loss: 0.0052 - dense_30_acc: 0.8711 - dense_31_acc: 0.8732 - dense_32_acc: 0.8719 - dense_33_acc: 0.9023 - dense_34_acc: 0.9345 - dense_35_acc: 0.9993 - val_loss: 1.5549 - val_dense_30_loss: 0.3495 - val_dense_31_loss: 0.3759 - val_dense_32_loss: 0.3857 - val_dense_33_loss: 0.2646 - val_dense_34_loss: 0.1759 - val_dense_35_loss: 0.0034 - val_dense_30_acc: 0.8980 - val_dense_31_acc: 0.8839 - val_dense_32_acc: 0.8809 - val_dense_33_acc: 0.9225 - val_dense_34_acc: 0.9434 - val_dense_35_acc: 0.9992\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 4s - loss: 1.4101 - dense_30_loss: 0.3358 - dense_31_loss: 0.3174 - dense_32_loss: 0.3456 - dense_33_loss: 0.2505 - dense_34_loss: 0.1575 - dense_35_loss: 0.0034 - dense_30_acc: 0.8966 - dense_31_acc: 0.9028 - dense_32_acc: 0.8938 - dense_33_acc: 0.9228 - dense_34_acc: 0.9508 - dense_35_acc: 0.9995 - val_loss: 1.3292 - val_dense_30_loss: 0.3013 - val_dense_31_loss: 0.2789 - val_dense_32_loss: 0.3399 - val_dense_33_loss: 0.2491 - val_dense_34_loss: 0.1555 - val_dense_35_loss: 0.0045 - val_dense_30_acc: 0.9128 - val_dense_31_acc: 0.9168 - val_dense_32_acc: 0.8984 - val_dense_33_acc: 0.9256 - val_dense_34_acc: 0.9501 - val_dense_35_acc: 0.9984\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 4s - loss: 1.1958 - dense_30_loss: 0.2837 - dense_31_loss: 0.2685 - dense_32_loss: 0.2936 - dense_33_loss: 0.2131 - dense_34_loss: 0.1345 - dense_35_loss: 0.0024 - dense_30_acc: 0.9128 - dense_31_acc: 0.9173 - dense_32_acc: 0.9092 - dense_33_acc: 0.9334 - dense_34_acc: 0.9580 - dense_35_acc: 0.9998 - val_loss: 1.2044 - val_dense_30_loss: 0.2733 - val_dense_31_loss: 0.2672 - val_dense_32_loss: 0.2927 - val_dense_33_loss: 0.2249 - val_dense_34_loss: 0.1442 - val_dense_35_loss: 0.0020 - val_dense_30_acc: 0.9143 - val_dense_31_acc: 0.9154 - val_dense_32_acc: 0.9125 - val_dense_33_acc: 0.9324 - val_dense_34_acc: 0.9536 - val_dense_35_acc: 0.9996\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 4s - loss: 1.0259 - dense_30_loss: 0.2405 - dense_31_loss: 0.2227 - dense_32_loss: 0.2525 - dense_33_loss: 0.1897 - dense_34_loss: 0.1184 - dense_35_loss: 0.0020 - dense_30_acc: 0.9254 - dense_31_acc: 0.9316 - dense_32_acc: 0.9236 - dense_33_acc: 0.9413 - dense_34_acc: 0.9637 - dense_35_acc: 0.9997 - val_loss: 1.0563 - val_dense_30_loss: 0.2354 - val_dense_31_loss: 0.2300 - val_dense_32_loss: 0.2605 - val_dense_33_loss: 0.2083 - val_dense_34_loss: 0.1202 - val_dense_35_loss: 0.0019 - val_dense_30_acc: 0.9311 - val_dense_31_acc: 0.9302 - val_dense_32_acc: 0.9234 - val_dense_33_acc: 0.9386 - val_dense_34_acc: 0.9620 - val_dense_35_acc: 0.9999\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 4s - loss: 0.8887 - dense_30_loss: 0.2052 - dense_31_loss: 0.1977 - dense_32_loss: 0.2160 - dense_33_loss: 0.1684 - dense_34_loss: 0.0998 - dense_35_loss: 0.0016 - dense_30_acc: 0.9365 - dense_31_acc: 0.9385 - dense_32_acc: 0.9338 - dense_33_acc: 0.9478 - dense_34_acc: 0.9696 - dense_35_acc: 0.9998 - val_loss: 1.0167 - val_dense_30_loss: 0.2182 - val_dense_31_loss: 0.2069 - val_dense_32_loss: 0.2597 - val_dense_33_loss: 0.2024 - val_dense_34_loss: 0.1282 - val_dense_35_loss: 0.0013 - val_dense_30_acc: 0.9348 - val_dense_31_acc: 0.9367 - val_dense_32_acc: 0.9186 - val_dense_33_acc: 0.9390 - val_dense_34_acc: 0.9605 - val_dense_35_acc: 1.0000\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 4s - loss: 0.7967 - dense_30_loss: 0.1825 - dense_31_loss: 0.1740 - dense_32_loss: 0.1953 - dense_33_loss: 0.1484 - dense_34_loss: 0.0948 - dense_35_loss: 0.0017 - dense_30_acc: 0.9433 - dense_31_acc: 0.9445 - dense_32_acc: 0.9390 - dense_33_acc: 0.9542 - dense_34_acc: 0.9699 - dense_35_acc: 0.9998 - val_loss: 0.9332 - val_dense_30_loss: 0.1974 - val_dense_31_loss: 0.1986 - val_dense_32_loss: 0.2289 - val_dense_33_loss: 0.1894 - val_dense_34_loss: 0.1178 - val_dense_35_loss: 0.0011 - val_dense_30_acc: 0.9408 - val_dense_31_acc: 0.9397 - val_dense_32_acc: 0.9325 - val_dense_33_acc: 0.9439 - val_dense_34_acc: 0.9612 - val_dense_35_acc: 0.9997\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 4s - loss: 0.7067 - dense_30_loss: 0.1570 - dense_31_loss: 0.1541 - dense_32_loss: 0.1776 - dense_33_loss: 0.1332 - dense_34_loss: 0.0835 - dense_35_loss: 0.0013 - dense_30_acc: 0.9510 - dense_31_acc: 0.9513 - dense_32_acc: 0.9440 - dense_33_acc: 0.9580 - dense_34_acc: 0.9731 - dense_35_acc: 0.9998 - val_loss: 0.8973 - val_dense_30_loss: 0.1788 - val_dense_31_loss: 0.1867 - val_dense_32_loss: 0.2257 - val_dense_33_loss: 0.1888 - val_dense_34_loss: 0.1162 - val_dense_35_loss: 0.0011 - val_dense_30_acc: 0.9454 - val_dense_31_acc: 0.9440 - val_dense_32_acc: 0.9340 - val_dense_33_acc: 0.9464 - val_dense_34_acc: 0.9635 - val_dense_35_acc: 0.9997\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 4s - loss: 0.6346 - dense_30_loss: 0.1406 - dense_31_loss: 0.1390 - dense_32_loss: 0.1580 - dense_33_loss: 0.1203 - dense_34_loss: 0.0758 - dense_35_loss: 9.8428e-04 - dense_30_acc: 0.9563 - dense_31_acc: 0.9561 - dense_32_acc: 0.9497 - dense_33_acc: 0.9610 - dense_34_acc: 0.9766 - dense_35_acc: 0.9999 - val_loss: 0.8547 - val_dense_30_loss: 0.1761 - val_dense_31_loss: 0.1802 - val_dense_32_loss: 0.2043 - val_dense_33_loss: 0.1845 - val_dense_34_loss: 0.1090 - val_dense_35_loss: 5.0428e-04 - val_dense_30_acc: 0.9459 - val_dense_31_acc: 0.9464 - val_dense_32_acc: 0.9401 - val_dense_33_acc: 0.9484 - val_dense_34_acc: 0.9661 - val_dense_35_acc: 0.9999\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 4s - loss: 0.5827 - dense_30_loss: 0.1355 - dense_31_loss: 0.1270 - dense_32_loss: 0.1424 - dense_33_loss: 0.1131 - dense_34_loss: 0.0637 - dense_35_loss: 9.3985e-04 - dense_30_acc: 0.9561 - dense_31_acc: 0.9598 - dense_32_acc: 0.9549 - dense_33_acc: 0.9647 - dense_34_acc: 0.9796 - dense_35_acc: 0.9999 - val_loss: 0.8785 - val_dense_30_loss: 0.1882 - val_dense_31_loss: 0.1958 - val_dense_32_loss: 0.1975 - val_dense_33_loss: 0.1815 - val_dense_34_loss: 0.1137 - val_dense_35_loss: 0.0016 - val_dense_30_acc: 0.9409 - val_dense_31_acc: 0.9404 - val_dense_32_acc: 0.9419 - val_dense_33_acc: 0.9500 - val_dense_34_acc: 0.9640 - val_dense_35_acc: 0.9995\n",
      "3000/4000 [=====================>........] - ETA: 0sdigit accuracy 0.94815\n",
      "sequence accuracy 0.76775\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "inception = inception(6)\n",
    "# Fit the model\n",
    "inception.fit(train_data, train_label_list, nb_epoch=10, batch_size=200, verbose=1, validation_split=.2)\n",
    "# Final evaluation of the model\n",
    "predictions = inception.predict(test_data,batch_size=200, verbose=1)\n",
    "combined_pred = np.array(predictions[0:5]).argmax(axis=2).T\n",
    "equiv = combined_pred==label_test[:,0:5]\n",
    "print 'digit accuracy' , float(np.sum(equiv))/(5*num_test)\n",
    "seq_acc = np.sum((equiv.sum(axis=1)==5))/float(num_test)\n",
    "print 'sequence accuracy' , seq_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## digit accuracy 0.94815 sequence accuracy 0.76775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def monster(num_outs):\n",
    "    input_img=Input(shape=(1,28,140))\n",
    "    tower_1 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\n",
    "    tower_1 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(tower_1)\n",
    "\n",
    "    tower_2 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(input_img)\n",
    "    tower_2 = Convolution2D(64, 5, 5, border_mode='same', activation='relu')(tower_2)\n",
    "\n",
    "    tower_3 = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same')(input_img)\n",
    "    tower_3 = Convolution2D(64, 1, 1, border_mode='same', activation='relu')(tower_3)\n",
    "\n",
    "    merged = concatenate([tower_1, tower_2, tower_3])\n",
    "    con1 = Convolution2D(30, 5, 5, border_mode='valid', activation='relu', dim_ordering=\"th\")(merged)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(con1)\n",
    "    con2 = Convolution2D(15, 3, 3, border_mode='valid', activation='relu', dim_ordering=\"th\")(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(con2)\n",
    "    drop = Dropout(0.2)(pool2)\n",
    "    flat = Flatten()(drop)\n",
    "    den1 = Dense(128, activation='relu')(flat)\n",
    "    den2 = Dense(128, activation='relu')(den1)\n",
    "    outputs = []\n",
    "    for itr in range(0,num_outs):\n",
    "        outputs.append(Dense(11, activation='softmax')(den2))\n",
    "    model = Model(input=input_img, output=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  \n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\")`\n",
      "  import sys\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), padding=\"same\", strides=(1, 1))`\n",
      "  if __name__ == '__main__':\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(30, (5, 5), padding=\"valid\", activation=\"relu\", data_format=\"channels_first\")`\n",
      "  del sys.path[0]\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  \n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(15, (3, 3), padding=\"valid\", activation=\"relu\", data_format=\"channels_first\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "  app.launch_new_instance()\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "/home/michael/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 25s - loss: 6.6014 - dense_54_loss: 1.5352 - dense_55_loss: 1.4361 - dense_56_loss: 1.3691 - dense_57_loss: 1.2463 - dense_58_loss: 0.8155 - dense_59_loss: 0.1992 - dense_54_acc: 0.4602 - dense_55_acc: 0.5023 - dense_56_acc: 0.5221 - dense_57_acc: 0.5727 - dense_58_acc: 0.7422 - dense_59_acc: 0.9502 - val_loss: 3.1605 - val_dense_54_loss: 0.7073 - val_dense_55_loss: 0.6810 - val_dense_56_loss: 0.6278 - val_dense_57_loss: 0.6130 - val_dense_58_loss: 0.5202 - val_dense_59_loss: 0.0112 - val_dense_54_acc: 0.7704 - val_dense_55_acc: 0.7759 - val_dense_56_acc: 0.8030 - val_dense_57_acc: 0.7954 - val_dense_58_acc: 0.8244 - val_dense_59_acc: 0.9964\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 25s - loss: 2.5289 - dense_54_loss: 0.5840 - dense_55_loss: 0.5583 - dense_56_loss: 0.5313 - dense_57_loss: 0.4701 - dense_58_loss: 0.3754 - dense_59_loss: 0.0098 - dense_54_acc: 0.8120 - dense_55_acc: 0.8233 - dense_56_acc: 0.8285 - dense_57_acc: 0.8448 - dense_58_acc: 0.8749 - dense_59_acc: 0.9968 - val_loss: 1.9848 - val_dense_54_loss: 0.4740 - val_dense_55_loss: 0.4525 - val_dense_56_loss: 0.4217 - val_dense_57_loss: 0.3605 - val_dense_58_loss: 0.2724 - val_dense_59_loss: 0.0036 - val_dense_54_acc: 0.8486 - val_dense_55_acc: 0.8560 - val_dense_56_acc: 0.8656 - val_dense_57_acc: 0.8880 - val_dense_58_acc: 0.9119 - val_dense_59_acc: 0.9992\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 25s - loss: 1.7190 - dense_54_loss: 0.4055 - dense_55_loss: 0.3903 - dense_56_loss: 0.3746 - dense_57_loss: 0.3115 - dense_58_loss: 0.2330 - dense_59_loss: 0.0041 - dense_54_acc: 0.8742 - dense_55_acc: 0.8779 - dense_56_acc: 0.8817 - dense_57_acc: 0.8988 - dense_58_acc: 0.9250 - dense_59_acc: 0.9988 - val_loss: 1.5472 - val_dense_54_loss: 0.3415 - val_dense_55_loss: 0.3750 - val_dense_56_loss: 0.3657 - val_dense_57_loss: 0.2642 - val_dense_58_loss: 0.1956 - val_dense_59_loss: 0.0051 - val_dense_54_acc: 0.8944 - val_dense_55_acc: 0.8737 - val_dense_56_acc: 0.8830 - val_dense_57_acc: 0.9169 - val_dense_58_acc: 0.9384 - val_dense_59_acc: 0.9986\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 24s - loss: 1.3352 - dense_54_loss: 0.3186 - dense_55_loss: 0.2995 - dense_56_loss: 0.2945 - dense_57_loss: 0.2326 - dense_58_loss: 0.1863 - dense_59_loss: 0.0037 - dense_54_acc: 0.8997 - dense_55_acc: 0.9060 - dense_56_acc: 0.9087 - dense_57_acc: 0.9261 - dense_58_acc: 0.9415 - dense_59_acc: 0.9988 - val_loss: 1.2883 - val_dense_54_loss: 0.3090 - val_dense_55_loss: 0.2840 - val_dense_56_loss: 0.2817 - val_dense_57_loss: 0.2429 - val_dense_58_loss: 0.1692 - val_dense_59_loss: 0.0015 - val_dense_54_acc: 0.9038 - val_dense_55_acc: 0.9108 - val_dense_56_acc: 0.9131 - val_dense_57_acc: 0.9266 - val_dense_58_acc: 0.9440 - val_dense_59_acc: 0.9995\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 24s - loss: 1.0909 - dense_54_loss: 0.2603 - dense_55_loss: 0.2412 - dense_56_loss: 0.2408 - dense_57_loss: 0.1964 - dense_58_loss: 0.1500 - dense_59_loss: 0.0023 - dense_54_acc: 0.9205 - dense_55_acc: 0.9248 - dense_56_acc: 0.9259 - dense_57_acc: 0.9388 - dense_58_acc: 0.9517 - dense_59_acc: 0.9994 - val_loss: 1.1444 - val_dense_54_loss: 0.2395 - val_dense_55_loss: 0.2441 - val_dense_56_loss: 0.2461 - val_dense_57_loss: 0.2484 - val_dense_58_loss: 0.1652 - val_dense_59_loss: 0.0011 - val_dense_54_acc: 0.9291 - val_dense_55_acc: 0.9220 - val_dense_56_acc: 0.9259 - val_dense_57_acc: 0.9244 - val_dense_58_acc: 0.9476 - val_dense_59_acc: 1.0000\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 24s - loss: 0.9211 - dense_54_loss: 0.2203 - dense_55_loss: 0.1976 - dense_56_loss: 0.1999 - dense_57_loss: 0.1678 - dense_58_loss: 0.1327 - dense_59_loss: 0.0028 - dense_54_acc: 0.9305 - dense_55_acc: 0.9383 - dense_56_acc: 0.9362 - dense_57_acc: 0.9466 - dense_58_acc: 0.9573 - dense_59_acc: 0.9992 - val_loss: 1.0409 - val_dense_54_loss: 0.2284 - val_dense_55_loss: 0.2404 - val_dense_56_loss: 0.2158 - val_dense_57_loss: 0.2148 - val_dense_58_loss: 0.1405 - val_dense_59_loss: 9.2452e-04 - val_dense_54_acc: 0.9314 - val_dense_55_acc: 0.9222 - val_dense_56_acc: 0.9327 - val_dense_57_acc: 0.9345 - val_dense_58_acc: 0.9554 - val_dense_59_acc: 0.9997\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 24s - loss: 0.7869 - dense_54_loss: 0.1841 - dense_55_loss: 0.1712 - dense_56_loss: 0.1760 - dense_57_loss: 0.1455 - dense_58_loss: 0.1085 - dense_59_loss: 0.0017 - dense_54_acc: 0.9433 - dense_55_acc: 0.9467 - dense_56_acc: 0.9439 - dense_57_acc: 0.9528 - dense_58_acc: 0.9654 - dense_59_acc: 0.9996 - val_loss: 0.9385 - val_dense_54_loss: 0.2289 - val_dense_55_loss: 0.2046 - val_dense_56_loss: 0.1866 - val_dense_57_loss: 0.1954 - val_dense_58_loss: 0.1225 - val_dense_59_loss: 5.4277e-04 - val_dense_54_acc: 0.9300 - val_dense_55_acc: 0.9370 - val_dense_56_acc: 0.9442 - val_dense_57_acc: 0.9410 - val_dense_58_acc: 0.9599 - val_dense_59_acc: 0.9999\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 24s - loss: 0.6711 - dense_54_loss: 0.1607 - dense_55_loss: 0.1416 - dense_56_loss: 0.1461 - dense_57_loss: 0.1272 - dense_58_loss: 0.0942 - dense_59_loss: 0.0014 - dense_54_acc: 0.9493 - dense_55_acc: 0.9550 - dense_56_acc: 0.9532 - dense_57_acc: 0.9599 - dense_58_acc: 0.9695 - dense_59_acc: 0.9995 - val_loss: 0.9490 - val_dense_54_loss: 0.2159 - val_dense_55_loss: 0.1842 - val_dense_56_loss: 0.2089 - val_dense_57_loss: 0.1955 - val_dense_58_loss: 0.1441 - val_dense_59_loss: 4.2248e-04 - val_dense_54_acc: 0.9354 - val_dense_55_acc: 0.9440 - val_dense_56_acc: 0.9415 - val_dense_57_acc: 0.9446 - val_dense_58_acc: 0.9544 - val_dense_59_acc: 0.9997\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 25s - loss: 0.6005 - dense_54_loss: 0.1390 - dense_55_loss: 0.1260 - dense_56_loss: 0.1302 - dense_57_loss: 0.1169 - dense_58_loss: 0.0870 - dense_59_loss: 0.0015 - dense_54_acc: 0.9559 - dense_55_acc: 0.9591 - dense_56_acc: 0.9587 - dense_57_acc: 0.9608 - dense_58_acc: 0.9716 - dense_59_acc: 0.9996 - val_loss: 0.8455 - val_dense_54_loss: 0.1864 - val_dense_55_loss: 0.1890 - val_dense_56_loss: 0.1651 - val_dense_57_loss: 0.1853 - val_dense_58_loss: 0.1192 - val_dense_59_loss: 5.0407e-04 - val_dense_54_acc: 0.9441 - val_dense_55_acc: 0.9405 - val_dense_56_acc: 0.9496 - val_dense_57_acc: 0.9451 - val_dense_58_acc: 0.9641 - val_dense_59_acc: 0.9997\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 24s - loss: 0.5174 - dense_54_loss: 0.1246 - dense_55_loss: 0.1114 - dense_56_loss: 0.1139 - dense_57_loss: 0.0950 - dense_58_loss: 0.0707 - dense_59_loss: 0.0017 - dense_54_acc: 0.9587 - dense_55_acc: 0.9627 - dense_56_acc: 0.9622 - dense_57_acc: 0.9679 - dense_58_acc: 0.9775 - dense_59_acc: 0.9996 - val_loss: 0.8282 - val_dense_54_loss: 0.1881 - val_dense_55_loss: 0.1744 - val_dense_56_loss: 0.1714 - val_dense_57_loss: 0.1813 - val_dense_58_loss: 0.1123 - val_dense_59_loss: 5.5078e-04 - val_dense_54_acc: 0.9448 - val_dense_55_acc: 0.9476 - val_dense_56_acc: 0.9480 - val_dense_57_acc: 0.9497 - val_dense_58_acc: 0.9652 - val_dense_59_acc: 1.0000\n",
      "3600/4000 [==========================>...] - ETA: 0sdigit accuracy 0.95325\n",
      "sequence accuracy 0.7875\n"
     ]
    }
   ],
   "source": [
    "# build the reall big model\n",
    "model = monster(6)\n",
    "# Fit the model\n",
    "model.fit(train_data, train_label_list, nb_epoch=10, batch_size=200, verbose=1, validation_split=.2)\n",
    "# Evaluate the model\n",
    "predictions = model.predict(test_data,batch_size=200, verbose=1)\n",
    "combined_pred = np.array(predictions[0:5]).argmax(axis=2).T\n",
    "equiv = combined_pred==label_test[:,0:5]\n",
    "print 'digit accuracy' , float(np.sum(equiv))/(5*num_test)\n",
    "seq_acc = np.sum((equiv.sum(axis=1)==5))/float(num_test)\n",
    "print 'sequence accuracy' , seq_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## digit accuracy 0.95325 sequence accuracy 0.7875"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupytertf",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
